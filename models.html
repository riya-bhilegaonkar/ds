<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Code: Tested Classification Models</title>

<script src="site_libs/header-attrs-2.18/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/journal.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Home</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="report.html">Final Model</a>
</li>
<li>
  <a href="models.html">Code: Tested Classification Models</a>
</li>
<li>
  <a href="http://github.com/riya-bhilegaonkar/">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">

<div class="btn-group pull-right float-right">
<button type="button" class="btn btn-default btn-xs btn-secondary btn-sm dropdown-toggle" data-toggle="dropdown" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu dropdown-menu-right" style="min-width: 50px;">
<li><a id="rmd-show-all-code" href="#">Show All Code</a></li>
<li><a id="rmd-hide-all-code" href="#">Hide All Code</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Code: Tested Classification Models</h1>

</div>


<p>The below is the code used to test the chosen classification
model:</p>
<pre class="r"><code>#Load Libraries
library(chunked)</code></pre>
<pre><code>## Loading required package: dplyr</code></pre>
<pre><code>## 
## Attaching package: &#39;dplyr&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     filter, lag</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     intersect, setdiff, setequal, union</code></pre>
<pre class="r"><code>library(tidyverse)</code></pre>
<pre><code>## ── Attaching packages
## ───────────────────────────────────────
## tidyverse 1.3.2 ──</code></pre>
<pre><code>## ✔ ggplot2 3.4.0     ✔ purrr   0.3.5
## ✔ tibble  3.1.8     ✔ stringr 1.5.0
## ✔ tidyr   1.2.1     ✔ forcats 0.5.2
## ✔ readr   2.1.3     
## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
## ✖ dplyr::filter() masks stats::filter()
## ✖ dplyr::lag()    masks stats::lag()</code></pre>
<pre class="r"><code>library(caret)</code></pre>
<pre><code>## Loading required package: lattice
## 
## Attaching package: &#39;caret&#39;
## 
## The following object is masked from &#39;package:purrr&#39;:
## 
##     lift</code></pre>
<pre class="r"><code>library(FNN)
library(doBy)</code></pre>
<pre><code>## 
## Attaching package: &#39;doBy&#39;
## 
## The following object is masked from &#39;package:dplyr&#39;:
## 
##     order_by</code></pre>
<pre class="r"><code>library(data.table)</code></pre>
<pre><code>## 
## Attaching package: &#39;data.table&#39;
## 
## The following object is masked from &#39;package:purrr&#39;:
## 
##     transpose
## 
## The following objects are masked from &#39;package:dplyr&#39;:
## 
##     between, first, last</code></pre>
<pre class="r"><code>library(h2o)</code></pre>
<pre><code>## 
## ----------------------------------------------------------------------
## 
## Your next step is to start H2O:
##     &gt; h2o.init()
## 
## For H2O package documentation, ask for help:
##     &gt; ??h2o
## 
## After starting H2O, you can use the Web UI at http://localhost:54321
## For more information visit https://docs.h2o.ai
## 
## ----------------------------------------------------------------------
## 
## 
## Attaching package: &#39;h2o&#39;
## 
## The following objects are masked from &#39;package:data.table&#39;:
## 
##     hour, month, week, year
## 
## The following objects are masked from &#39;package:stats&#39;:
## 
##     cor, sd, var
## 
## The following objects are masked from &#39;package:base&#39;:
## 
##     %*%, %in%, &amp;&amp;, ||, apply, as.factor, as.numeric, colnames,
##     colnames&lt;-, ifelse, is.character, is.factor, is.numeric, log,
##     log10, log1p, log2, round, signif, trunc</code></pre>
<pre class="r"><code>library(gtsummary)
library(e1071)
library(mice)</code></pre>
<pre><code>## 
## Attaching package: &#39;mice&#39;
## 
## The following object is masked from &#39;package:stats&#39;:
## 
##     filter
## 
## The following objects are masked from &#39;package:base&#39;:
## 
##     cbind, rbind</code></pre>
<pre class="r"><code>library(corrplot)</code></pre>
<pre><code>## corrplot 0.92 loaded</code></pre>
<pre class="r"><code>#for reproducibility
set.seed(4)</code></pre>
<pre class="r"><code>#Data Preparation
diabetes_risk &lt;- fread(&quot;data/diabetes_risk_data.csv&quot;) %&gt;% rename(member_id = 1) %&gt;% mutate(gender = recode(
    gender,
    &quot;Male&quot; = 0,
    &quot;Female&quot; = 1), gluc = na_if(gluc, 0)) %&gt;% mutate(diabetes = as.factor(diabetes), gender = as.factor(gender), cholesterol = as.factor(cholesterol), gluc = as.factor(gluc), smoke = as.factor(smoke), active = as.factor(active), alco = as.factor(alco), age = as.integer(age/365), height = height/2.54, weight = weight*2.20462)

diabetes_risk &lt;- diabetes_risk %&gt;% mutate(ap_hi = replace(ap_hi, ap_hi&gt;360, NA), ap_lo = replace(ap_lo, ap_lo&gt;360, NA), ap_hi = replace(ap_hi, ap_hi&lt;0, NA), ap_lo = replace(ap_lo, ap_lo&lt;0, NA))

# Define arbitrary matrix with TRUE values when data is missing and FALSE otherwise
A &lt;- is.na(diabetes_risk)
# Replace all the other columns which are not the one you want to impute (let say column 2)
A[,-c(6:9)] &lt;- FALSE 
# Run the mice function
imputed &lt;- mice(diabetes_risk, where = A)</code></pre>
<pre><code>## 
##  iter imp variable
##   1   1  ap_hi  ap_lo  cholesterol  gluc
##   1   2  ap_hi  ap_lo  cholesterol  gluc
##   1   3  ap_hi  ap_lo  cholesterol  gluc
##   1   4  ap_hi  ap_lo  cholesterol  gluc
##   1   5  ap_hi  ap_lo  cholesterol  gluc
##   2   1  ap_hi  ap_lo  cholesterol  gluc
##   2   2  ap_hi  ap_lo  cholesterol  gluc
##   2   3  ap_hi  ap_lo  cholesterol  gluc
##   2   4  ap_hi  ap_lo  cholesterol  gluc
##   2   5  ap_hi  ap_lo  cholesterol  gluc
##   3   1  ap_hi  ap_lo  cholesterol  gluc
##   3   2  ap_hi  ap_lo  cholesterol  gluc
##   3   3  ap_hi  ap_lo  cholesterol  gluc
##   3   4  ap_hi  ap_lo  cholesterol  gluc
##   3   5  ap_hi  ap_lo  cholesterol  gluc
##   4   1  ap_hi  ap_lo  cholesterol  gluc
##   4   2  ap_hi  ap_lo  cholesterol  gluc
##   4   3  ap_hi  ap_lo  cholesterol  gluc
##   4   4  ap_hi  ap_lo  cholesterol  gluc
##   4   5  ap_hi  ap_lo  cholesterol  gluc
##   5   1  ap_hi  ap_lo  cholesterol  gluc
##   5   2  ap_hi  ap_lo  cholesterol  gluc
##   5   3  ap_hi  ap_lo  cholesterol  gluc
##   5   4  ap_hi  ap_lo  cholesterol  gluc
##   5   5  ap_hi  ap_lo  cholesterol  gluc</code></pre>
<pre><code>## Warning: Number of logged events: 1</code></pre>
<pre class="r"><code>imputed &lt;- complete(imputed)


#Data Partition
indexTrain &lt;- createDataPartition(y = imputed$diabetes, p = 0.8, list = FALSE)
trainData &lt;- imputed[indexTrain, ]
testData &lt;- imputed[-indexTrain, ]

#for model training (remove id variable)
trainData &lt;- trainData[,-1]
testData &lt;- testData[-1]

#checking for outliers 
cooksd &lt;- cooks.distance(glm(diabetes ~ ., 
                             family = &quot;binomial&quot;, 
                             data = trainData))

plot(cooksd, 
     pch=&quot;*&quot;, 
     cex=2, 
     main=&quot;Influential Obs by Cooks distance&quot;)  
abline(h = 4*mean(cooksd, na.rm=T), col=&quot;red&quot;)</code></pre>
<p><img src="models_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<pre class="r"><code>outliers &lt;- as.data.frame(rownames(trainData[cooksd &gt; 4*mean(cooksd, na.rm=T), ]))
nrow(outliers)</code></pre>
<pre><code>## [1] 2278</code></pre>
<pre class="r"><code>#Checking for multicolinearity (#bmi and weight are correlated)
corrplot(cor(trainData[,c(1,3:6,13)]), method = &quot;circle&quot;, type = &quot;full&quot;)</code></pre>
<p><img src="models_files/figure-html/unnamed-chunk-2-2.png" width="672" /></p>
<pre class="r"><code>cor.test(trainData$weight, trainData$bmi)</code></pre>
<pre><code>## 
##  Pearson&#39;s product-moment correlation
## 
## data:  trainData$weight and trainData$bmi
## t = 273.65, df = 55999, p-value &lt; 2.2e-16
## alternative hypothesis: true correlation is not equal to 0
## 95 percent confidence interval:
##  0.7528381 0.7599256
## sample estimates:
##      cor 
## 0.756404</code></pre>
<pre class="r"><code>#for h2o package
localH2O &lt;- h2o.init(nthreads = -1)</code></pre>
<pre><code>##  Connection successful!
## 
## R is connected to the H2O cluster: 
##     H2O cluster uptime:         1 days 8 hours 
##     H2O cluster timezone:       America/New_York 
##     H2O data parsing timezone:  UTC 
##     H2O cluster version:        3.40.0.1 
##     H2O cluster version age:    18 days 
##     H2O cluster name:           H2O_started_from_R_Riya_Bhilegaonkar_goj840 
##     H2O cluster total nodes:    1 
##     H2O cluster total memory:   1.63 GB 
##     H2O cluster total cores:    4 
##     H2O cluster allowed cores:  4 
##     H2O cluster healthy:        TRUE 
##     H2O Connection ip:          localhost 
##     H2O Connection port:        54321 
##     H2O Connection proxy:       NA 
##     H2O Internal Security:      FALSE 
##     R Version:                  R version 4.2.2 (2022-10-31 ucrt)</code></pre>
<pre class="r"><code>#data as h2o cluster
train.h2o &lt;- as.h2o(trainData)</code></pre>
<pre><code>## 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |======================================================================| 100%</code></pre>
<pre class="r"><code>test.h2o &lt;- as.h2o(testData)</code></pre>
<pre><code>## 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |======================================================================| 100%</code></pre>
<pre class="r"><code>#dependent variable (Purchase)
y.dep &lt;- 12

#independent variables 
x.indep &lt;- c(1:11)</code></pre>
<pre class="r"><code>#Model Training with Random Forest
rforest.model &lt;- h2o.randomForest(y=y.dep, x=x.indep, training_frame = train.h2o, ntrees = 1000, mtries = 3, max_depth = 4, seed = 4)</code></pre>
<pre><code>## 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |===                                                                   |   4%
  |                                                                            
  |=======                                                               |  10%
  |                                                                            
  |==================                                                    |  26%
  |                                                                            
  |==============================                                        |  43%
  |                                                                            
  |==========================================                            |  60%
  |                                                                            
  |=======================================================               |  79%
  |                                                                            
  |====================================================================  |  97%
  |                                                                            
  |======================================================================| 100%</code></pre>
<pre class="r"><code>#Performance Metrics
h2o.performance(rforest.model, newdata = test.h2o)</code></pre>
<pre><code>## H2OBinomialMetrics: drf
## 
## MSE:  0.1858085
## RMSE:  0.4310551
## LogLoss:  0.5557967
## Mean Per-Class Error:  0.2907277
## AUC:  0.7988383
## AUCPR:  0.7850693
## Gini:  0.5976766
## R^2:  0.2567657
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##           0    1    Error         Rate
## 0      4109 2895 0.413335   =2895/7004
## 1      1176 5819 0.168120   =1176/6995
## Totals 5285 8714 0.290806  =4071/13999
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold       value idx
## 1                       max f1  0.388012    0.740849 270
## 2                       max f2  0.264126    0.842748 366
## 3                 max f0point5  0.558867    0.749887 171
## 4                 max accuracy  0.514926    0.731481 193
## 5                max precision  0.830560    0.945455   3
## 6                   max recall  0.214128    1.000000 399
## 7              max specificity  0.837575    0.999714   0
## 8             max absolute_mcc  0.536997    0.469217 183
## 9   max min_per_class_accuracy  0.430935    0.726805 234
## 10 max mean_per_class_accuracy  0.514926    0.731431 193
## 11                     max tns  0.837575 7002.000000   0
## 12                     max fns  0.837575 6992.000000   0
## 13                     max fps  0.214128 7004.000000 399
## 14                     max tps  0.214128 6995.000000 399
## 15                     max tnr  0.837575    0.999714   0
## 16                     max fnr  0.837575    0.999571   0
## 17                     max fpr  0.214128    1.000000 399
## 18                     max tpr  0.214128    1.000000 399
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`</code></pre>
<pre class="r"><code>#Model Training with Logistic Regression
logit.model &lt;- h2o.glm( x = x.indep,
                                y = y.dep, 
                               training_frame = train.h2o, 
                               seed = 4,
                               family = &quot;binomial&quot;,
                               lambda_search = TRUE,
                               alpha = 0.5, 
                               nfolds = 5 )</code></pre>
<pre><code>## 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |====================                                                  |  29%
  |                                                                            
  |========================================                              |  58%
  |                                                                            
  |======================================================================| 100%</code></pre>
<pre><code>## Warning in doTryCatch(return(expr), name, parentenv, handler): Reached maximum
## number of iterations 91!</code></pre>
<pre class="r"><code>#Model Coefficients
h2o.coef(logit.model)</code></pre>
<pre><code>##     Intercept cholesterol.1 cholesterol.2 cholesterol.3        gluc.1 
## -10.184925589  -0.414970055   0.000000000   0.598659783   0.002281884 
##        gluc.2        gluc.3      gender.0      gender.1       smoke.0 
##   0.000000000  -0.254656842   0.012018009  -0.001971860   0.000000000 
##       smoke.1        alco.0        alco.1      active.0      active.1 
##  -0.119400754   0.000000000  -0.139148905   0.121567468  -0.068637182 
##           age        height        weight         ap_hi         ap_lo 
##   0.050635173  -0.009047809   0.005377703   0.045928578   0.021325318</code></pre>
<pre class="r"><code>#Performance Metrics
h2o.performance(logit.model, newdata = test.h2o)</code></pre>
<pre><code>## H2OBinomialMetrics: glm
## 
## MSE:  0.1863812
## RMSE:  0.4317189
## LogLoss:  0.5613453
## Mean Per-Class Error:  0.2854534
## AUC:  0.7941346
## AUCPR:  0.7779681
## Gini:  0.5882693
## R^2:  0.254475
## Residual Deviance:  15716.55
## AIC:  15748.55
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##           0    1    Error         Rate
## 0      4275 2729 0.389634   =2729/7004
## 1      1268 5727 0.181272   =1268/6995
## Totals 5543 8456 0.285520  =3997/13999
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold       value idx
## 1                       max f1  0.404325    0.741311 244
## 2                       max f2  0.184963    0.839597 350
## 3                 max f0point5  0.532431    0.742238 181
## 4                 max accuracy  0.475876    0.729909 208
## 5                max precision  0.896496    0.886228  33
## 6                   max recall  0.003682    1.000000 399
## 7              max specificity  0.997319    0.999572   0
## 8             max absolute_mcc  0.475876    0.460121 208
## 9   max min_per_class_accuracy  0.462930    0.728441 214
## 10 max mean_per_class_accuracy  0.475876    0.729897 208
## 11                     max tns  0.997319 7001.000000   0
## 12                     max fns  0.997319 6986.000000   0
## 13                     max fps  0.003682 7004.000000 399
## 14                     max tps  0.003682 6995.000000 399
## 15                     max tnr  0.997319    0.999572   0
## 16                     max fnr  0.997319    0.998713   0
## 17                     max fpr  0.003682    1.000000 399
## 18                     max tpr  0.003682    1.000000 399
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`</code></pre>
<pre class="r"><code>#Model Training with SVM
letter_classifier &lt;- ksvm(diabetes ~ ., data = trainData,kernel = &quot;vanilladot&quot;)
letter_classifier

#predictions:
letter_predictions &lt;- predict(letter_classifier, testData)

#Check the accuracy:
caret::confusionMatrix(letter_predictions,testData$diabetes)
agreement &lt;- letter_predictions == testData$diabetes
prop.table(table(agreement))</code></pre>
<pre class="r"><code>#Model Training with Naive Bayes
naive.h2o &lt;- h2o.naiveBayes(x = x.indep,
                          y = y.dep,
                          training_frame = train.h2o,
                          laplace = 0,
                          nfolds = 5,
                          seed = 4)</code></pre>
<pre><code>## 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |======================================================================| 100%</code></pre>
<pre class="r"><code>#Performance Metrics
h2o.performance(naive.h2o, newdata = test.h2o)</code></pre>
<pre><code>## H2OBinomialMetrics: naivebayes
## 
## MSE:  0.1961914
## RMSE:  0.4429349
## LogLoss:  0.6355006
## Mean Per-Class Error:  0.3044981
## AUC:  0.7885875
## AUCPR:  0.7667358
## Gini:  0.5771751
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##           0    1    Error         Rate
## 0      3835 3169 0.452456   =3169/7004
## 1      1095 5900 0.156540   =1095/6995
## Totals 4930 9069 0.304593  =4264/13999
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold       value idx
## 1                       max f1  0.243398    0.734562 290
## 2                       max f2  0.087084    0.844731 368
## 3                 max f0point5  0.518093    0.737772 179
## 4                 max accuracy  0.430442    0.723195 208
## 5                max precision  0.986199    0.856607  10
## 6                   max recall  0.029355    1.000000 396
## 7              max specificity  0.999791    0.993004   0
## 8             max absolute_mcc  0.467997    0.450836 196
## 9   max min_per_class_accuracy  0.357329    0.721302 236
## 10 max mean_per_class_accuracy  0.368108    0.723189 231
## 11                     max tns  0.999791 6955.000000   0
## 12                     max fns  0.999791 6718.000000   0
## 13                     max fps  0.022575 7004.000000 399
## 14                     max tps  0.029355 6995.000000 396
## 15                     max tnr  0.999791    0.993004   0
## 16                     max fnr  0.999791    0.960400   0
## 17                     max fpr  0.022575    1.000000 399
## 18                     max tpr  0.029355    1.000000 396
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`</code></pre>
<pre class="r"><code>tree.model = h2o.gbm(x = x.indep, 
                     y = y.dep, 
                        training_frame = train.h2o,
                        ntrees = 1, min_rows = 1, 
                        sample_rate = 1,            
                        col_sample_rate = 1,
                        max_depth = 5,
                        seed = 4)</code></pre>
<pre><code>## 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |======================================================================| 100%</code></pre>
<pre class="r"><code>#Performance Metrics
h2o.performance(tree.model, newdata = test.h2o)</code></pre>
<pre><code>## H2OBinomialMetrics: gbm
## 
## MSE:  0.237094
## RMSE:  0.486923
## LogLoss:  0.6673006
## Mean Per-Class Error:  0.2864475
## AUC:  0.7962068
## AUCPR:  0.7810849
## Gini:  0.5924137
## R^2:  0.05162349
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##           0    1    Error         Rate
## 0      4203 2801 0.399914   =2801/7004
## 1      1210 5785 0.172981   =1210/6995
## Totals 5413 8586 0.286520  =4011/13999
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold       value idx
## 1                       max f1  0.490039    0.742571  25
## 2                       max f2  0.469875    0.839554  30
## 3                 max f0point5  0.503653    0.751670  21
## 4                 max accuracy  0.499927    0.734338  22
## 5                max precision  0.536258    0.871381   1
## 6                   max recall  0.463250    1.000000  31
## 7              max specificity  0.549571    0.999857   0
## 8             max absolute_mcc  0.503653    0.474256  21
## 9   max min_per_class_accuracy  0.490762    0.731582  24
## 10 max mean_per_class_accuracy  0.499927    0.734305  22
## 11                     max tns  0.549571 7003.000000   0
## 12                     max fns  0.549571 6990.000000   0
## 13                     max fps  0.463250 7004.000000  31
## 14                     max tps  0.463250 6995.000000  31
## 15                     max tnr  0.549571    0.999857   0
## 16                     max fnr  0.549571    0.999285   0
## 17                     max fpr  0.463250    1.000000  31
## 18                     max tpr  0.463250    1.000000  31
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`</code></pre>
<pre class="r"><code># Build and train the model:
pros_gbm = h2o.gbm(x = x.indep, 
                     y = y.dep, 
                        training_frame = train.h2o,
                         nfolds = 5,
                         keep_cross_validation_predictions = TRUE,
                        seed = 4)</code></pre>
<pre><code>## 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |===========                                                           |  16%
  |                                                                            
  |==================================================                    |  71%
  |                                                                            
  |=========================================================             |  81%
  |                                                                            
  |================================================================      |  92%
  |                                                                            
  |======================================================================| 100%</code></pre>
<pre class="r"><code># Eval performance:
perf &lt;- h2o.performance(pros_gbm)

# Generate predictions on a validation set (if necessary):
pred &lt;- h2o.predict(pros_gbm, newdata = test.h2o)</code></pre>
<pre><code>## 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |======================================================================| 100%</code></pre>
<pre class="r"><code># Extract feature interactions:
feature_interactions &lt;- h2o.feature_interaction(pros_gbm)
pros_gbm</code></pre>
<pre><code>## Model Details:
## ==============
## 
## H2OBinomialModel: gbm
## Model ID:  GBM_model_R_1677358306266_4069 
## Model Summary: 
##   number_of_trees number_of_internal_trees model_size_in_bytes min_depth
## 1              50                       50               21837         5
##   max_depth mean_depth min_leaves max_leaves mean_leaves
## 1         5    5.00000         23         32    30.08000
## 
## 
## H2OBinomialMetrics: gbm
## ** Reported on training data. **
## 
## MSE:  0.1767536
## RMSE:  0.4204207
## LogLoss:  0.5316235
## Mean Per-Class Error:  0.2750871
## AUC:  0.8108858
## AUCPR:  0.8042745
## Gini:  0.6217715
## R^2:  0.2929855
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##            0     1    Error          Rate
## 0      17892 10125 0.361388  =10125/28017
## 1       5283 22701 0.188786   =5283/27984
## Totals 23175 32826 0.275138  =15408/56001
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold        value idx
## 1                       max f1  0.374308     0.746621 246
## 2                       max f2  0.191470     0.844934 342
## 3                 max f0point5  0.590491     0.759887 148
## 4                 max accuracy  0.505924     0.741290 184
## 5                max precision  0.920899     1.000000   0
## 6                   max recall  0.063426     1.000000 397
## 7              max specificity  0.920899     1.000000   0
## 8             max absolute_mcc  0.558328     0.486171 162
## 9   max min_per_class_accuracy  0.460420     0.738659 206
## 10 max mean_per_class_accuracy  0.505924     0.741261 184
## 11                     max tns  0.920899 28017.000000   0
## 12                     max fns  0.920899 27978.000000   0
## 13                     max fps  0.053583 28017.000000 399
## 14                     max tps  0.063426 27984.000000 397
## 15                     max tnr  0.920899     1.000000   0
## 16                     max fnr  0.920899     0.999786   0
## 17                     max fpr  0.053583     1.000000 399
## 18                     max tpr  0.063426     1.000000 397
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`
## 
## H2OBinomialMetrics: gbm
## ** Reported on cross-validation data. **
## ** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **
## 
## MSE:  0.1802601
## RMSE:  0.4245705
## LogLoss:  0.5405513
## Mean Per-Class Error:  0.2878734
## AUC:  0.8019388
## AUCPR:  0.787266
## Gini:  0.6038776
## R^2:  0.2789592
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##            0     1    Error          Rate
## 0      16726 11291 0.403005  =11291/28017
## 1       4834 23150 0.172742   =4834/27984
## Totals 21560 34441 0.287941  =16125/56001
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold        value idx
## 1                       max f1  0.362441     0.741690 249
## 2                       max f2  0.164773     0.842250 352
## 3                 max f0point5  0.618983     0.753749 134
## 4                 max accuracy  0.514275     0.735290 176
## 5                max precision  0.943138     1.000000   0
## 6                   max recall  0.060544     1.000000 397
## 7              max specificity  0.943138     1.000000   0
## 8             max absolute_mcc  0.556247     0.475213 159
## 9   max min_per_class_accuracy  0.458922     0.733305 203
## 10 max mean_per_class_accuracy  0.514275     0.735257 176
## 11                     max tns  0.943138 28017.000000   0
## 12                     max fns  0.943138 27982.000000   0
## 13                     max fps  0.049953 28017.000000 399
## 14                     max tps  0.060544 27984.000000 397
## 15                     max tnr  0.943138     1.000000   0
## 16                     max fnr  0.943138     0.999929   0
## 17                     max fpr  0.049953     1.000000 399
## 18                     max tpr  0.060544     1.000000 397
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`
## Cross-Validation Metrics Summary: 
##                                mean        sd  cv_1_valid  cv_2_valid
## accuracy                   0.722484  0.003802    0.721084    0.724913
## auc                        0.802067  0.004431    0.803046    0.800809
## err                        0.277516  0.003802    0.278916    0.275087
## err_count               3108.400000 58.487606 3130.000000 3084.000000
## f0point5                   0.711579  0.007713    0.707063    0.717102
## f1                         0.742668  0.001732    0.742090    0.742140
## f2                         0.776830  0.012465    0.780768    0.768991
## lift_top_group             1.795018  0.059649    1.783900    1.849663
## logloss                    0.540571  0.004330    0.540096    0.540740
## max_per_class_error        0.356326  0.027759    0.365340    0.338770
## mcc                        0.451268  0.003169    0.450129    0.453000
## mean_per_class_accuracy    0.722619  0.003367    0.721767    0.724613
## mean_per_class_error       0.277381  0.003367    0.278233    0.275387
## mse                        0.180268  0.001763    0.179995    0.180409
## pr_auc                     0.787779  0.005998    0.785418    0.791057
## precision                  0.692348  0.012857    0.685492    0.701327
## r2                         0.278898  0.007048    0.279976    0.278348
## recall                     0.801564  0.021097    0.808874    0.787997
## rmse                       0.424576  0.002079    0.424258    0.424746
## specificity                0.643675  0.027759    0.634660    0.661230
##                          cv_3_valid  cv_4_valid  cv_5_valid
## accuracy                   0.716614    0.723530    0.726278
## auc                        0.809275    0.798487    0.798716
## err                        0.283386    0.276470    0.273722
## err_count               3200.000000 3076.000000 3052.000000
## f0point5                   0.700138    0.715870    0.717722
## f1                         0.745223    0.743324    0.740564
## f2                         0.796514    0.772969    0.764908
## lift_top_group             1.800366    1.700227    1.840937
## logloss                    0.533640    0.544705    0.543674
## max_per_class_error        0.399930    0.348196    0.329391
## mcc                        0.447041    0.450696    0.455472
## mean_per_class_accuracy    0.717445    0.722942    0.726328
## mean_per_class_error       0.282555    0.277058    0.273672
## mse                        0.177471    0.182063    0.181403
## pr_auc                     0.796671    0.782416    0.783335
## precision                  0.672994    0.698667    0.703261
## r2                         0.290081    0.271699    0.274386
## recall                     0.834820    0.794081    0.782047
## rmse                       0.421273    0.426688    0.425915
## specificity                0.600070    0.651803    0.670609</code></pre>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeCodeFolding("hide" === "show");
});
</script>

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
